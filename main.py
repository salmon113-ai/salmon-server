import streamlit as st
from langchain_core.messages.chat import ChatMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

st.title("ğŸŸSalmon Project #1")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

def print_message():
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)
        
def add_message(role, message):
    st.session_state["messages"].append(ChatMessage(role=role, content=message))

def create_chain():
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ì§§ê²Œ ë‹µë³€í•˜ì„¸ìš”."),
        ("user", "#Question:\n{question}")
    ])
    # LM studioì—ì„œ ëª¨ë¸ ì„ íƒ í›„ Local server ê¸°ë™ í•„ìš”
    llm = ChatOpenAI(base_url="http://localhost:1234/v1", api_key="lm-studio")
    output_parser = StrOutputParser()
    
    chain = prompt | llm | output_parser
    return chain
    
    
user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”.")

print_message()

if user_input:
    st.chat_message("user").write(user_input)
    
    chain = create_chain()
    ai_answer = chain.invoke({"question": user_input})
    st.chat_message("assistant").write(ai_answer)
    
    add_message("user", user_input)
    add_message("assistant", user_input)
    
